# ISLR-python
This repository contains Python code for a selection of tables, figures and LAB sections from the book <A href='http://www-bcf.usc.edu/%7Egareth/ISL/index.html'>'An Introduction to Statistical Learning with Applications in R'</A> by James, Witten, Hastie, Tibshirani (2013).<P>
This great book gives a thorough introduction to the field of Statistical/Machine Learning. The book is available for download (see link below), but I think this is one those books that is definitely worth buying. The book contains sections with applications in R based on public datasets available for download or which are part of the R-package ISLR. Since Python is my language of choice for data analysis, I decided to try and rework some of the figures and calculations in IPython Notebook using:

<UL>
<LI>pandas
<LI>numpy
<LI>scikit-learn
<LI>matplotlib
<LI>seaborn
<LI>statsmodels
<LI>patsy
</UL>
<A href='http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Python%20module%20versions.ipynb'>(Module versions used)</A>

I thought it to be a good way to learn more about Machine Learning in Python by creating these notebooks. I created some of the figures/tables of the chapters and worked through some LAB sections. I realize that at certain points it may look like I tried too hard to make the output identical to the tables and R-plots in the book. But I did this to explore some details of the libraries mentioned above (mostly matplotlib). Note that this repository is <STRONG>not a tutorial</STRONG> and that you probably should have a copy of the book to follow along.<BR>
<BR> Work in process! Suggestions for improvement and help with unsolved issues are welcome!<P>

<A href='http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Chapter%203.ipynb'>Chapter 3 - Linear Regression</A><BR>
<A href='http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Chapter%204.ipynb'>Chapter 4 - Classification</A><BR>
<A href='http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Chapter%205.ipynb'>Chapter 5 - Resampling Methods</A><BR>
<A href='http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Chapter%206.ipynb'>Chapter 6 - Linear Model Selection and Regularization</A><BR>
<A href='http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Chapter%207.ipynb'>Chapter 7 - Moving Beyond Linearity</A><BR>
<A href='http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Chapter%208.ipynb'>Chapter 8 - Tree-Based Methods</A><BR>
<A href='http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Chapter%209.ipynb'>Chapter 9 - Support Vector Machines</A><BR>
<A href='http://nbviewer.ipython.org/github/JWarmenhoven/ISL-python/blob/master/Chapter%2010.ipynb'>Chapter 10 - Unsupervised Learning</A><BR>

For an advanced treatment of these topics see Hastie et al. (2009)

#####References:
James, G., Witten, D., Hastie, T., Tibshirani, R. (2013). <I>An Introduction to Statistical Learning with Applications in  R</I>,  Springer Science+Business Media, New York.
http://www-bcf.usc.edu/~gareth/ISL/index.html

Hastie, T., Tibshirani, R., Friedman, J. (2009). <I>Elements of Statistical Learning</I>, Second Edition, Springer Science+Business Media, New York.
http://http://statweb.stanford.edu/~tibs/ElemStatLearn/
